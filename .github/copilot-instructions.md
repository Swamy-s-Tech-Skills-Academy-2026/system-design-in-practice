# GitHub Copilot Instructions for Prompt Engineering Playbook

**Version**: 1.0  
**Last Updated**: December 2025  
**Repository**: `prompt-engineering-playbook`

---

## ğŸ¯ Repository Purpose

**Prompt Engineering Playbook** is a comprehensive playbook that standardizes how prompts are designed, developed, tested, and integrated across C#, Python, and Postman workflows using Azure OpenAI.

### What This Repository Provides

- **Standard Prompt Patterns**: Instruction-based, role-based, RAG, chain-of-thought, evaluation prompts
- **Reusable Templates**: Summarization, classification, extraction, transformation, code-generation
- **Governance Guidelines**: Review workflows, storage strategy, safety considerations, quality guidelines
- **Code Integration Examples**: Working samples in Python, C#, and Postman for Azure OpenAI
- **Infrastructure Guidance**: Azure OpenAI setup and configuration

### Target Audience

- Engineering teams working with Azure OpenAI
- Prompt engineers
- AI application developers
- Technical leads and architects

### Business Value

- Ensures uniformity across prompt engineering practices
- Reduces model misbehaviour through tested patterns
- Accelerates onboarding for new team members
- Improves productivity with reusable templates
- Provides consistent framework for enterprise-grade Azure OpenAI development

---

## ğŸ“ Repository Structure

```text
prompt-engineering-playbook/
â”œâ”€â”€ .github/
â”‚   â”œâ”€â”€ workflows/
â”‚   â”‚   â”œâ”€â”€ ci-python.yml              # Python linting and testing
â”‚   â”‚   â”œâ”€â”€ ci-dotnet.yml              # .NET build and testing
â”‚   â”‚   â””â”€â”€ validate-postman.yml       # Postman collection validation
â”‚   â”œâ”€â”€ ISSUE_TEMPLATE/
â”‚   â”œâ”€â”€ PULL_REQUEST_TEMPLATE.md
â”‚   â””â”€â”€ copilot-instructions.md        # THIS FILE
â”œâ”€â”€ playbook/                          # Core playbook framework
â”‚   â”œâ”€â”€ 01-overview.md                 # Introduction and getting started
â”‚   â”œâ”€â”€ 02-structure-and-toc.md        # Table of contents
â”‚   â”œâ”€â”€ 03-patterns-and-anti-patterns.md  # Prompt patterns
â”‚   â”œâ”€â”€ 04-templates.md                # Reusable templates
â”‚   â”œâ”€â”€ 05-governance.md               # Governance guidelines
â”‚   â””â”€â”€ 06-evaluation-and-testing.md   # Testing approaches
â”œâ”€â”€ src/                               # Code examples
â”‚   â”œâ”€â”€ python/
â”‚   â”‚   â”œâ”€â”€ README.md
â”‚   â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”‚   â””â”€â”€ samples/                   # Python sample scripts
â”‚   â”œâ”€â”€ csharp/
â”‚   â”‚   â”œâ”€â”€ README.md
â”‚   â”‚   â””â”€â”€ samples/                   # C# sample projects
â”‚   â””â”€â”€ postman/
â”‚       â”œâ”€â”€ README.md
â”‚       â”œâ”€â”€ prompt-playbook.postman_collection.json
â”‚       â””â”€â”€ prompt-playbook.postman_environment.json
â”œâ”€â”€ infra/                             # Infrastructure guidance
â”‚   â””â”€â”€ azure-guidance.md
â”œâ”€â”€ docs/                              # Additional documentation
â”‚   â””â”€â”€ architecture-diagrams/
â”œâ”€â”€ README.md
â”œâ”€â”€ LICENSE
â”œâ”€â”€ CONTRIBUTING.md
â””â”€â”€ CODE_OF_CONDUCT.md
```

---

## ğŸ”§ Development Guidelines

### When Working with Prompts

1. **Follow Established Patterns**: Use patterns from `playbook/02-patterns-and-anti-patterns.md`
2. **Use Templates**: Leverage templates from `playbook/03-templates.md`
3. **Apply Governance**: Follow guidelines in `playbook/04-governance.md`
4. **Test Thoroughly**: Use evaluation approaches from `playbook/05-evaluation-and-testing.md`

### When Writing Code Examples

#### Python Examples (`src/python/`)

- Use Azure OpenAI SDK (`openai` package with Azure configuration)
- Follow PEP 8 style guidelines
- Include proper error handling and logging
- Use environment variables for configuration (never hardcode keys)
- Include docstrings and type hints

#### C# Examples (`src/csharp/`)

- Use Azure.AI.OpenAI NuGet package
- Follow .NET coding conventions
- Implement proper exception handling
- Use configuration providers (appsettings.json, environment variables)
- Include XML documentation comments

#### Postman Examples (`src/postman/`)

- Use environment variables for endpoints and keys
- Include pre-request scripts for authentication
- Add test scripts for response validation
- Document expected responses

### Security Best Practices

- âŒ **NEVER** commit API keys or secrets
- âœ… **ALWAYS** use environment variables or Azure Key Vault
- âœ… **ALWAYS** add `.env` files to `.gitignore`
- âœ… **ALWAYS** use GitHub Secrets for CI/CD workflows

### Configuration Management

```bash
# Required environment variables
AZURE_OPENAI_ENDPOINT=https://your-resource.openai.azure.com/
AZURE_OPENAI_KEY=your-key-here
AZURE_OPENAI_DEPLOYMENT_NAME=your-deployment-name
AZURE_OPENAI_API_VERSION=2024-02-15-preview
```

---

## ğŸ“‹ Code Quality Standards

### Markdown Files

- Use proper heading hierarchy (H1 â†’ H2 â†’ H3)
- Include code fence language specifications
- Follow markdownlint rules
- Use UTF-8 encoding

### Python Code

- Run `flake8` for linting
- Run `pytest` for testing
- Use `black` for formatting
- Maintain `requirements.txt` with pinned versions

### C# Code

- Build with `dotnet build`
- Run tests with `dotnet test`
- Follow .NET naming conventions
- Keep NuGet packages updated

### Postman Collections

- Validate with Newman
- Include comprehensive test scripts
- Document all variables
- Use collection-level authentication

---

## ğŸš€ CI/CD Workflows

### Python CI (`ci-python.yml`)

- Triggered on push/PR to `main`
- Sets up Python environment
- Installs dependencies
- Runs linting (flake8)
- Runs tests (pytest)

### .NET CI (`ci-dotnet.yml`)

- Triggered on push/PR to `main`
- Sets up .NET SDK
- Restores NuGet packages
- Builds solution
- Runs tests

### Postman Validation (`validate-postman.yml`)

- Triggered on push/PR to `main`
- Installs Newman
- Validates collection structure
- Runs collection tests (with mock or staging endpoint)

---

## ğŸ“ Local Quality Checks

Before committing changes, run these quality checks to ensure documentation meets standards:

### Markdown Linting

Run markdownlint to check all markdown files for style and formatting issues:

```bash
npx markdownlint-cli2 "**/*.md"
```

**Note**: Uses `.markdownlint-cli2.yaml` for configuration. The tool automatically reads `.markdownlint.json` for rule settings.

**Common Issues to Fix:**

- Missing language specification in code fences (MD040)
- Missing blank lines around headings/lists/fences (MD022/MD031/MD032)
- Incorrect list indentation (MD007 - use 2 spaces)

### Link Checking (Lychee via Docker)

Run Lychee via Docker to check for broken links in markdown files:

```bash
docker run --rm -v "${PWD}:/input:ro" lycheeverse/lychee --config /input/lychee.toml "/input/**/*.md"
```

**Note**: Requires Docker to be installed and running. The configuration file `lychee.toml` at the repository root defines excluded patterns and timeout settings.

### Pre-Commit Checklist

Before committing documentation changes:

- [ ] Run markdownlint and fix any issues
- [ ] Run Lychee link checker (if Docker available)
- [ ] Verify all file references point to existing files
- [ ] Check that code fences have language specifications
- [ ] Ensure proper blank lines around headings and lists

---

## ï¿½ğŸ“ Prompt Engineering Best Practices

### Prompt Structure

1. **Role Definition**: Define the AI's role and expertise
2. **Context Setting**: Provide relevant background information
3. **Task Description**: Clearly state what needs to be done
4. **Output Format**: Specify expected response format
5. **Constraints**: Define limitations and guardrails
6. **Examples**: Provide few-shot examples when helpful

### Common Patterns

| Pattern           | Use Case               | Example                                |
| ----------------- | ---------------------- | -------------------------------------- |
| Instruction-based | Direct task completion | "Summarize the following text..."      |
| Role-based        | Specialized expertise  | "You are a senior code reviewer..."    |
| Chain-of-thought  | Complex reasoning      | "Think step by step..."                |
| RAG               | Knowledge-grounded     | "Based on the following context..."    |
| Evaluation        | Quality assessment     | "Rate the following on a scale..."     |

### Anti-Patterns to Avoid

- âŒ Vague or ambiguous instructions
- âŒ Missing output format specification
- âŒ No error handling guidance
- âŒ Overly complex single prompts
- âŒ Hardcoded values instead of variables

---

## ğŸ”— Quick Links

- [Playbook Overview](../playbook/01-overview.md)
- [Prompt Patterns](../playbook/03-patterns-and-anti-patterns.md)
- [Templates](../playbook/04-templates.md)
- [Governance](../playbook/05-governance.md)
- [Python Examples](../src/python/README.md)
- [C# Examples](../src/csharp/README.md)
- [Azure Setup](../infra/azure-guidance.md)

---

## ğŸ“ Support

- **Issues**: Use GitHub Issues for bug reports and feature requests
- **Discussions**: Use GitHub Discussions for questions and ideas
- **Contributing**: See [CONTRIBUTING.md](../CONTRIBUTING.md) for guidelines
